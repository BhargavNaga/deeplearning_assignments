{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4449be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca572289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "     ..\n",
      "95    1\n",
      "96    1\n",
      "97    1\n",
      "98    1\n",
      "99    1\n",
      "Name: Species, Length: 100, dtype: int32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
       "0             5.1           3.5            1.4           0.2        0\n",
       "1             4.9           3.0            1.4           0.2        0\n",
       "2             4.7           3.2            1.3           0.2        0\n",
       "3             4.6           3.1            1.5           0.2        0\n",
       "4             5.0           3.6            1.4           0.2        0\n",
       "..            ...           ...            ...           ...      ...\n",
       "95            5.7           3.0            4.2           1.2        1\n",
       "96            5.7           2.9            4.2           1.3        1\n",
       "97            6.2           2.9            4.3           1.3        1\n",
       "98            5.1           2.5            3.0           1.1        1\n",
       "99            5.7           2.8            4.1           1.3        1\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the Iris dataset\n",
    "data = pd.read_csv(\"iris.csv\")\n",
    "data.head(5)\n",
    "\n",
    "# Drop the \"Id\" column and encode the target variable\n",
    "data = data.drop(\"Id\", axis=1)\n",
    "data = data[data[\"Species\"].isin([\"Iris-setosa\", \"Iris-versicolor\"])]\n",
    "data[\"Species\"] = np.where(data[\"Species\"] == \"Iris-setosa\", 0, 1)\n",
    "print(data[\"Species\"])\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deef5e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 4) (20, 4) (80,) (20,)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the rows\n",
    "np.random.seed(42)  # for reproducibility\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "x_train = data.iloc[:80, :-1].values\n",
    "x_test = data.iloc[80:, :-1].values\n",
    "\n",
    "y_train = data.iloc[:80, -1].values\n",
    "y_test = data.iloc[80:, -1].values\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "663b3b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b8440c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 5) (20, 5) (80,) (20,)\n"
     ]
    }
   ],
   "source": [
    "# Add a bias term to the input features\n",
    "x_train = np.c_[np.ones(x_train.shape[0]), x_train]\n",
    "x_test = np.c_[np.ones(x_test.shape[0]), x_test]\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91b27e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.09932891 -0.43764323  1.34172064  1.1474489 ]\n",
      " [ 1.         -0.03025676 -0.23047484  1.20204901  1.32534795]\n",
      " [ 1.         -0.83710367 -0.02330644 -0.89302552 -1.1652388 ]\n",
      " [ 1.         -1.15984243  0.18386195 -0.8231897  -0.98733975]\n",
      " [ 1.         -0.83710367 -0.23047484 -0.96286133 -0.98733975]\n",
      " [ 1.          2.39028396 -0.02330644  1.48139228  1.32534795]\n",
      " [ 1.         -0.5143649   1.21970391 -0.89302552 -0.63154164]\n",
      " [ 1.         -1.15984243  0.18386195 -1.03269715 -0.98733975]\n",
      " [ 1.         -0.5143649   0.39103034 -0.75335388 -0.45364259]\n",
      " [ 1.          1.42206768 -1.68065358  1.13221319  0.96954984]\n",
      " [ 1.          1.09932891 -0.23047484  1.27188483  1.1474489 ]\n",
      " [ 1.          1.58343706 -0.43764323  1.06237737  0.96954984]\n",
      " [ 1.          2.0675452  -0.02330644  1.34172064  1.32534795]\n",
      " [ 1.          0.61522077 -0.85198001  0.7830341   0.79165079]\n",
      " [ 1.         -0.03025676  0.59819873 -0.75335388 -0.98733975]\n",
      " [ 1.         -0.67573429 -2.30215876  0.50369083  0.43585268]\n",
      " [ 1.          1.09932891 -0.64481162  0.85286992  0.96954984]\n",
      " [ 1.          0.61522077  1.84120909 -1.10253297 -0.98733975]\n",
      " [ 1.          0.61522077 -1.05914841  0.85286992  0.79165079]\n",
      " [ 1.          1.58343706  0.18386195  1.20204901  1.32534795]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7c5d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights():\n",
    "    return np.zeros(x_train.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0c4377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(weights, inputs):\n",
    "    return np.dot(inputs, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb7b07d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(predictions, targets):\n",
    "    return np.mean((predictions - targets) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52504ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(weights, inputs, predictions, targets, learning_rate):\n",
    "    gradient = np.dot(inputs.T, predictions - targets) / len(targets)\n",
    "    weights -= learning_rate * gradient\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7066382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(x_train, y_train, learning_rate, epochs):\n",
    "    weights = initialize_weights()\n",
    "    print(weights)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        predictions = predict(weights, x_train)\n",
    "        print(f\"predictions epoch -{epoch} \", predictions)\n",
    "        loss = mse_loss(predictions, y_train)\n",
    "        print(f\"loss epoch -{epoch} \", loss)\n",
    "        \n",
    "        # Check for convergence (you can modify this condition based on your requirements)\n",
    "        if loss < 0.001:\n",
    "            print(f\"Converged at epoch {epoch + 1}. MSE Loss: {loss}\")\n",
    "            break\n",
    "\n",
    "        weights = update_weights(weights, x_train, predictions, y_train, learning_rate)\n",
    "        print(f\"weights epoch -{epoch} \", weights)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44e1033a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0.]\n",
      "predictions epoch -0  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss epoch -0  0.475\n",
      "weights epoch -0  [ 4.75000000e-05  3.60811852e-05 -3.45129593e-05  4.83678507e-05\n",
      "  4.78326082e-05]\n",
      "predictions epoch -1  [ 2.61058645e-04  1.97862610e-04  2.26371602e-04 -6.58609151e-05\n",
      " -8.01952562e-05 -8.21252641e-05 -1.42426287e-04  1.66938248e-04\n",
      " -8.61080514e-05 -9.26530668e-05 -6.05258575e-05 -7.47646684e-05\n",
      "  2.12182313e-04 -1.19413433e-04  1.81414485e-04 -1.05625460e-04\n",
      "  2.73335663e-04  2.85497020e-04 -8.28796666e-05 -4.76393170e-05\n",
      "  1.90646478e-04  1.57012857e-04 -6.75511027e-05 -1.15337682e-04\n",
      "  1.68988460e-04 -1.01672064e-04 -9.33438980e-05  1.73363058e-04\n",
      " -8.08294540e-05  2.77560837e-04 -9.62146513e-05 -1.00315077e-04\n",
      "  1.90741835e-04 -7.96806739e-05  1.19577832e-04 -7.66336717e-05\n",
      "  1.87542842e-04  2.32552048e-04 -8.37810992e-05 -9.01449053e-05\n",
      " -8.41754767e-05 -8.08294540e-05 -8.79476626e-05  1.57703688e-04\n",
      " -8.34528599e-05 -1.02215866e-04  1.55051064e-04 -5.59698770e-05\n",
      "  2.08596470e-04 -1.22125084e-04 -8.60812261e-05 -8.97872739e-05\n",
      " -8.41436910e-05 -1.01037693e-04 -9.05098907e-05  2.17982431e-04\n",
      " -1.06105689e-04  1.47273810e-04 -7.27412810e-05  1.83562622e-04\n",
      "  2.22114642e-04  1.77135244e-04  2.57622226e-04 -5.76823456e-05\n",
      "  2.53002674e-04  1.64579510e-04 -1.07347433e-04  2.79677188e-04\n",
      "  1.94876613e-04  2.05852860e-04  1.45640255e-04 -3.66559590e-05\n",
      "  2.39275879e-04 -9.19304499e-05  1.09476192e-04  1.06605439e-04\n",
      "  2.33879643e-04 -1.34862201e-04  1.81840649e-04  1.56927005e-04]\n",
      "loss epoch -1  0.47481249078063537\n",
      "weights epoch -1  [ 9.49952500e-05  7.21503778e-05 -6.90160644e-05  9.67211778e-05\n",
      "  9.56509060e-05]\n",
      "predictions epoch -2  [ 5.22047841e-04  3.95676075e-04  4.52683848e-04 -1.31691310e-04\n",
      " -1.60357083e-04 -1.64216116e-04 -2.84799332e-04  3.33836512e-04\n",
      " -1.72181371e-04 -1.85268665e-04 -1.21025322e-04 -1.49496257e-04\n",
      "  4.24309523e-04 -2.38782848e-04  3.62784439e-04 -2.11209474e-04\n",
      "  5.46596570e-04  5.70915636e-04 -1.65723721e-04 -9.52551188e-05\n",
      "  3.81245076e-04  3.13987910e-04 -1.35071964e-04 -2.30629459e-04\n",
      "  3.37936029e-04 -2.03306004e-04 -1.86649924e-04  3.46683322e-04\n",
      " -1.61624204e-04  5.55046910e-04 -1.92390099e-04 -2.00589133e-04\n",
      "  3.81434596e-04 -1.59327856e-04  2.39130931e-04 -1.53235649e-04\n",
      "  3.75038732e-04  4.65041457e-04 -1.67526891e-04 -1.80254059e-04\n",
      " -1.68315633e-04 -1.61624204e-04 -1.75858978e-04  3.15369169e-04\n",
      " -1.66871201e-04 -2.04391698e-04  3.10065704e-04 -1.11912587e-04\n",
      "  4.17139715e-04 -2.44201838e-04 -1.72126291e-04 -1.79536584e-04\n",
      " -1.68252460e-04 -2.02033565e-04 -1.80981016e-04  4.35908126e-04\n",
      " -2.12168822e-04  2.94512845e-04 -1.45451821e-04  3.67080181e-04\n",
      "  4.44170334e-04  3.54226666e-04  5.15174985e-04 -1.15337499e-04\n",
      "  5.05935903e-04  3.29118858e-04 -2.14653302e-04  5.59279479e-04\n",
      "  3.89703510e-04  4.11652233e-04  2.91246328e-04 -7.32888681e-05\n",
      "  4.78487488e-04 -1.83824233e-04  2.18930297e-04  2.13190123e-04\n",
      "  4.67696542e-04 -2.69675089e-04  3.63636354e-04  3.13817305e-04]\n",
      "loss epoch -2  0.4746250769503135\n",
      "weights epoch -2  [ 0.00014249  0.00010821 -0.00010351  0.00014506  0.00014345]\n",
      "predictions epoch -3  [ 0.00078297  0.00059344  0.00067894 -0.00019749 -0.00024049 -0.00024627\n",
      " -0.00042712  0.00050069 -0.00025822 -0.00027785 -0.0001815  -0.00022419\n",
      "  0.00063638 -0.00035811  0.00054411 -0.00031675  0.00081978  0.00085626\n",
      " -0.00024853 -0.00014285  0.0005718   0.00047093 -0.00020256 -0.00034588\n",
      "  0.00050684 -0.0003049  -0.00027992  0.00051996 -0.00024238  0.00083246\n",
      " -0.00028853 -0.00030082  0.00057208 -0.00023894  0.00035866 -0.00022981\n",
      "  0.00056249  0.00069747 -0.00025124 -0.00027033 -0.00025242 -0.00024238\n",
      " -0.00026373  0.000473   -0.00025026 -0.00030653  0.00046504 -0.00016783\n",
      "  0.00062563 -0.00036623 -0.00025814 -0.00026925 -0.00025233 -0.00030299\n",
      " -0.00027141  0.00065378 -0.00031819  0.00044172 -0.00021813  0.00055055\n",
      "  0.00066617  0.00053127  0.00077266 -0.00017297  0.0007588   0.00049362\n",
      " -0.00032192  0.00083881  0.00058448  0.0006174   0.00043682 -0.0001099\n",
      "  0.00071763 -0.00027568  0.00032836  0.00031975  0.00070145 -0.00040444\n",
      "  0.00054539  0.00047067]\n",
      "loss epoch -3  0.47443775845472214\n",
      "weights epoch -3  [ 0.00018997  0.00014425 -0.00013799  0.00019338  0.00019124]\n",
      "predictions epoch -4  [ 0.00104382  0.00079116  0.00090513 -0.00026326 -0.00032058 -0.00032829\n",
      " -0.00056939  0.00066751 -0.00034422 -0.00037039 -0.00024195 -0.00029886\n",
      "  0.0008484  -0.00047739  0.00072539 -0.00042225  0.00109289  0.00114152\n",
      " -0.00033131 -0.00019042  0.0007623   0.00062782 -0.00027002 -0.00046108\n",
      "  0.00067571 -0.00040646 -0.00037315  0.0006932  -0.00032311  0.00110979\n",
      " -0.00038462 -0.00040101  0.00076267 -0.00031852  0.00047816 -0.00030634\n",
      "  0.00074989  0.00092983 -0.00033491 -0.00036037 -0.00033649 -0.00032311\n",
      " -0.00035157  0.00063059 -0.0003336  -0.00040862  0.00061999 -0.00022372\n",
      "  0.00083407 -0.00048821 -0.00034411 -0.00035892 -0.00033637 -0.0004039\n",
      " -0.00036181  0.00087159 -0.00042417  0.00058889 -0.00029078  0.00073398\n",
      "  0.0008881   0.00070828  0.00103007 -0.00023057  0.00101159  0.00065808\n",
      " -0.00042914  0.00111826  0.00077921  0.00082309  0.00058236 -0.00014649\n",
      "  0.00095672 -0.0003675   0.00043777  0.0004263   0.00093514 -0.00053915\n",
      "  0.00072709  0.00062749]\n",
      "loss epoch -4  0.47425053523958083\n",
      "weights epoch -4  [ 0.00023745  0.00018029 -0.00017247  0.00024169  0.00023902]\n",
      "predictions epoch -5  [ 0.0013046   0.00098882  0.00113126 -0.000329   -0.00040064 -0.00041028\n",
      " -0.0007116   0.00083429 -0.00043019 -0.00046289 -0.00030237 -0.00037349\n",
      "  0.00106036 -0.00059663  0.00090663 -0.00052771  0.00136593  0.0014267\n",
      " -0.00041404 -0.00023796  0.00095275  0.00078469 -0.00033745 -0.00057623\n",
      "  0.00084453 -0.00050798 -0.00046634  0.00086639 -0.0004038   0.00138706\n",
      " -0.00048068 -0.00050117  0.00095322 -0.00039807  0.00059764 -0.00038285\n",
      "  0.00093724  0.00116213 -0.00041855 -0.00045037 -0.00042052 -0.0004038\n",
      " -0.00043937  0.00078814 -0.00041692 -0.00051068  0.00077489 -0.00027958\n",
      "  0.00104245 -0.00061014 -0.00043004 -0.00044856 -0.00042037 -0.00050477\n",
      " -0.00045216  0.00108934 -0.0005301   0.00073602 -0.0003634   0.00091736\n",
      "  0.00110998  0.00088524  0.00128742 -0.00028814  0.00126432  0.0008225\n",
      " -0.00053632  0.00139764  0.00097389  0.00102873  0.00072786 -0.00018305\n",
      "  0.00119574 -0.00045929  0.00054716  0.00053282  0.00116877 -0.00067382\n",
      "  0.00090875  0.00078427]\n",
      "loss epoch -5  0.4740634072506415\n",
      "weights epoch -5  [ 0.00028493  0.00021631 -0.00020693  0.00028999  0.00028678]\n",
      "predictions epoch -6  [ 0.00156531  0.00118644  0.00135734 -0.00039471 -0.00048067 -0.00049224\n",
      " -0.00085376  0.00100103 -0.00051613 -0.00055536 -0.00036276 -0.00044809\n",
      "  0.00127227 -0.00071582  0.00108782 -0.00063313  0.00163889  0.00171181\n",
      " -0.00049674 -0.00028548  0.00114316  0.00094151 -0.00040485 -0.00069134\n",
      "  0.00101332 -0.00060946 -0.0005595   0.00103954 -0.00048446  0.00166424\n",
      " -0.0005767  -0.00060128  0.00114372 -0.00047758  0.0007171  -0.00045933\n",
      "  0.00112455  0.00139437 -0.00050216 -0.00054033 -0.00050452 -0.00048446\n",
      " -0.00052714  0.00094565 -0.0005002  -0.00061269  0.00092976 -0.00033541\n",
      "  0.00125078 -0.00073203 -0.00051595 -0.00053815 -0.00050434 -0.0006056\n",
      " -0.00054248  0.00130704 -0.000636    0.00088312 -0.00043599  0.0011007\n",
      "  0.0013318   0.00106215  0.00154469 -0.00034569  0.00151697  0.00098687\n",
      " -0.00064346  0.00167694  0.00116851  0.00123432  0.00087333 -0.00021959\n",
      "  0.00143469 -0.00055103  0.00065653  0.00063932  0.00140234 -0.00080843\n",
      "  0.00109037  0.00094101]\n",
      "loss epoch -6  0.4738763744336888\n",
      "weights epoch -6  [ 0.0003324   0.00025232 -0.00024138  0.00033827  0.00033453]\n",
      "predictions epoch -7  [ 0.00182595  0.00138401  0.00158336 -0.00046039 -0.00056067 -0.00057415\n",
      " -0.00099587  0.00116773 -0.00060203 -0.00064779 -0.00042313 -0.00052266\n",
      "  0.00148412 -0.00083497  0.00126897 -0.00073851  0.00191178  0.00199683\n",
      " -0.00057941 -0.00033298  0.00133352  0.0010983  -0.00047222 -0.0008064\n",
      "  0.00118206 -0.0007109  -0.00065261  0.00121264 -0.00056508  0.00194136\n",
      " -0.00067268 -0.00070134  0.00133416 -0.00055706  0.00083653 -0.00053577\n",
      "  0.00131181  0.00162655 -0.00058573 -0.00063026 -0.00058849 -0.00056508\n",
      " -0.00061487  0.00110312 -0.00058345 -0.00071467  0.00108459 -0.00039122\n",
      "  0.00145906 -0.00085386 -0.00060181 -0.00062771 -0.00058827 -0.00070639\n",
      " -0.00063276  0.00152469 -0.00074185  0.00103019 -0.00050854  0.00128399\n",
      "  0.00155357  0.00123903  0.0018019  -0.00040321  0.00176956  0.00115121\n",
      " -0.00075056  0.00195617  0.00136309  0.00143985  0.00101876 -0.00025611\n",
      "  0.00167358 -0.00064274  0.00076587  0.0007458   0.00163584 -0.000943\n",
      "  0.00127194  0.00109772]\n",
      "loss epoch -7  0.47368943673453856\n",
      "weights epoch -7  [ 0.00037987  0.00028831 -0.00027583  0.00038654  0.00038226]\n",
      "predictions epoch -8  [ 0.00208653  0.00158153  0.00180931 -0.00052603 -0.00064063 -0.00065604\n",
      " -0.00113792  0.00133439 -0.00068789 -0.00074018 -0.00048347 -0.00059719\n",
      "  0.00169592 -0.00095408  0.00145007 -0.00084384  0.00218459  0.00228178\n",
      " -0.00066204 -0.00038046  0.00152383  0.00125504 -0.00053956 -0.00092142\n",
      "  0.00135076 -0.00081231 -0.00074569  0.00138571 -0.00064566  0.00221839\n",
      " -0.00076862 -0.00080137  0.00152456 -0.00063651  0.00095593 -0.00061218\n",
      "  0.00149903  0.00185866 -0.00066926 -0.00072016 -0.00067242 -0.00064566\n",
      " -0.00070256  0.00126056 -0.00066666 -0.00081661  0.00123939 -0.000447\n",
      "  0.00166728 -0.00097565 -0.00068764 -0.00071724 -0.00067217 -0.00080713\n",
      " -0.00072299  0.00174227 -0.00084765  0.00117722 -0.00058107  0.00146724\n",
      "  0.00177527  0.00141586  0.00205903 -0.0004607   0.00202208  0.00131551\n",
      " -0.00085762  0.00223532  0.00155762  0.00164533  0.00116417 -0.0002926\n",
      "  0.00191241 -0.00073442  0.00087519  0.00085226  0.00186928 -0.00107752\n",
      "  0.00145347  0.00125439]\n",
      "loss epoch -8  0.4735025940990402\n",
      "weights epoch -8  [ 0.00042733  0.0003243  -0.00031026  0.00043479  0.00042998]\n",
      "predictions epoch -9  [ 0.00234703  0.001779    0.00203521 -0.00059165 -0.00072055 -0.00073789\n",
      " -0.00127992  0.00150101 -0.00077372 -0.00083253 -0.00054378 -0.00067169\n",
      "  0.00190766 -0.00107314  0.00163113 -0.00094914  0.00245733  0.00256665\n",
      " -0.00074464 -0.00042791  0.0017141   0.00141176 -0.00060687 -0.00103639\n",
      "  0.00151942 -0.00091368 -0.00083873  0.00155873 -0.00072622  0.00249536\n",
      " -0.00086452 -0.00090136  0.00171491 -0.00071592  0.00107531 -0.00068856\n",
      "  0.0016862   0.00209071 -0.00075276 -0.00081002 -0.00075631 -0.00072622\n",
      " -0.00079022  0.00141796 -0.00074983 -0.0009185   0.00139415 -0.00050275\n",
      "  0.00187545 -0.00109739 -0.00077343 -0.00080672 -0.00075604 -0.00090783\n",
      " -0.00081319  0.0019598  -0.00095342  0.00132421 -0.00065357  0.00165044\n",
      "  0.00199691  0.00159264  0.0023161  -0.00051816  0.00227453  0.00147977\n",
      " -0.00096463  0.0025144   0.0017521   0.00185075  0.00130953 -0.00032907\n",
      "  0.00215117 -0.00082606  0.00098449  0.0009587   0.00210266 -0.00121199\n",
      "  0.00163495  0.00141102]\n",
      "loss epoch -9  0.47331584647307423\n",
      "weights epoch -9  [ 0.00047479  0.00036027 -0.00034469  0.00048303  0.00047768]\n",
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "def step_function(predictions):\n",
    "    return np.where(predictions <= 0, 0, 1)\n",
    "\n",
    "# Train the perceptron\n",
    "weights = train_perceptron(x_train, y_train, learning_rate=0.0001, epochs=10)\n",
    "\n",
    "# Test the trained perceptron on the test set\n",
    "test_predictions = step_function(predict(weights, x_test))\n",
    "accuracy = np.mean(test_predictions == y_test) * 100\n",
    "print(f\"Accuracy: {accuracy}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
